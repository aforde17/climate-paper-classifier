{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from processing import Processing\n",
    "from classifier import CNN\n",
    "from processing import Processing\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from processing import Processing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "embed_len = 128\n",
    "max_tokens = 50\n",
    "# source: https://coderzcolumn.com/tutorials/artificial-intelligence/pytorch-conv1d-for-text-classification\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.data = Processing()\n",
    "        self.data.process_all()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(self.data.vocab), embedding_dim=128)\n",
    "        self.conv1 = nn.Conv1d(128, 32, kernel_size=7, padding=\"same\")\n",
    "        self.linear = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        x = self.embedding_layer(X_batch)\n",
    "        # Transpose the tensor to shape [16, 128, 930]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x, _ = x.max(dim=-1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "class DatasetMaper(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds, losses = [],[],[]\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6115\n",
      "Train Loss : 1.348\n",
      "Valid Loss : 1.100\n",
      "Valid Acc  : 0.579\n",
      "Train Loss : 0.914\n",
      "Valid Loss : 0.919\n",
      "Valid Acc  : 0.669\n",
      "Train Loss : 0.649\n",
      "Valid Loss : 0.843\n",
      "Valid Acc  : 0.712\n"
     ]
    }
   ],
   "source": [
    "# Model      \n",
    "model = CNN()\n",
    "# Opmization function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Data\n",
    "data = model.data\n",
    "\n",
    "# Initialize dataset maper\n",
    "train = DatasetMaper(data.x_train, data.y_train)\n",
    "test = DatasetMaper(data.x_test, data.y_test)\n",
    "\n",
    "# Initialize loaders\n",
    "loader_train = DataLoader(train, batch_size=16)\n",
    "loader_test = DataLoader(test, batch_size=16)\n",
    "\n",
    "epochs = 3\n",
    "learning_rate = 1e-3\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    losses = []\n",
    "    for X, Y in loader_train:\n",
    "        Y_preds = model(X)\n",
    "        loss = loss_fn(Y_preds, Y)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "    \n",
    "    CalcValLossAndAccuracy(model, loss_fn, loader_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capp30255",
   "language": "python",
   "name": "capp30255"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
